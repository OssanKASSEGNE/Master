{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2 Ossan KASSEGNE : Classifieur Bay√©sien "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.metrics' has no attribute 'jaccard_similarity_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-00ecce991132>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfusionMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas_ml/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#!/usr/bin/env python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelSeries\u001b[0m       \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minfo\u001b[0m                         \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__version__\u001b[0m     \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas_ml/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#!/usr/bin/env python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelFrame\u001b[0m       \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseries\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelSeries\u001b[0m     \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas_ml/core/frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimbaccessors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimbaccessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mskaccessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmaccessors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msmaccessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnsaccessors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msnsaccessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas_ml/skaccessors/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearModelMethods\u001b[0m                 \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mManifoldMethods\u001b[0m                        \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetricsMethods\u001b[0m                          \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelSelectionMethods\u001b[0m           \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeighborsMethods\u001b[0m                      \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas_ml/skaccessors/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    254\u001b[0m _true_pred_methods = (_classification_methods + _regression_methods\n\u001b[1;32m    255\u001b[0m                       + _cluster_methods)\n\u001b[0;32m--> 256\u001b[0;31m \u001b[0m_attach_methods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMetricsMethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_wrap_target_pred_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_true_pred_methods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas_ml/core/accessor.py\u001b[0m in \u001b[0;36m_attach_methods\u001b[0;34m(cls, wrap_func, methods)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0m_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} already has '{1}' method\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.metrics' has no attribute 'jaccard_similarity_score'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from math import pi,exp,sqrt\n",
    "from scipy.stats import multivariate_normal\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "#print (iris.data)\n",
    "#print(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ciris = np.c_[iris.data.reshape(len(iris.data), -1), iris.target.reshape(len(iris.target), -1)]\n",
    "np.random.seed(987654321)\n",
    "np.random.shuffle(Ciris)\n",
    "shuffledIrisData = Ciris[ :, :iris.data.size//len(iris.data)].reshape(iris.data.shape)\n",
    "shuffledIrisTarget = Ciris[ :, iris.data.size//len(iris.data) :].reshape(iris.target.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cr√©ation des corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData,devData,testData = shuffledIrisData[:100],shuffledIrisData[100:130],shuffledIrisData[130:]\n",
    "trainTarget,devTarget,testTarget = shuffledIrisTarget[:100],shuffledIrisTarget[100:130],shuffledIrisTarget[130:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase d'apprentissage (utilisation de sepal length et sepal width/ colonnes 0 et 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilit√© √† priori sur le mod√®le d'apprentissatige\n",
    "- On r√©cup√®re la probabilit√© √† priori de chaque classe dans le corpus d'apprentissage\n",
    "- Probabilit√©s √† priori\n",
    " Classe 0 =  0.32 \n",
    " Classe 1 =  0.37 \n",
    " Classe 2 =  0.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##On r√©cup√®re le nombre de classes 0,1 et 2\n",
    "total = trainTarget.size\n",
    "classes = list(trainTarget)\n",
    "proba_class0 = (classes.count(0))/total\n",
    "proba_class1 = (classes.count(1))/total\n",
    "proba_class2 = (classes.count(2))/total\n",
    "print(\"Probabilit√©s √† priori\\n\",\"Classe 0 = \",proba_class0,\"\\n\",\"Classe 1 = \",proba_class1,\"\\n\",\"Classe 2 = \",proba_class2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S√©paration du corpus d'apprentissage en fonction des classes\n",
    " On s√©pare les corpus d'apprentissage en fonction des 3 classes pour le calcul des moyennes et des matrices de covariance de chacune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFull = np.c_[trainData,trainTarget]\n",
    "train0,train1,train2 = [] ,[], []\n",
    "for i in range(0,100):\n",
    "    if(trainFull[i][4] == 0):\n",
    "        train0.append(trainFull[i])\n",
    "    elif (trainFull[i][4] == 1):\n",
    "        train1.append(trainFull[i])\n",
    "    else :\n",
    "        train2.append(trainFull[i])\n",
    "train0 = np.array(train0)\n",
    "train1 = np.array(train1)\n",
    "train2 = np.array(train2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moyennes, Sigma suivant le descripteur \"sepal length\" et \"sepal width\" en fonction des classes\n",
    "On calcule le vecteur des moyennes et la matrices de covariance de chaque classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp = sepal length , sw = sepal width\n",
    "\n",
    "def moy(corpus, col1,col2):    #Retourne le vecteur des moyennes d'un corpus\n",
    "    return np.r_[np.mean(corpus[:,col1]),np.mean(corpus[:,col2])]\n",
    "\n",
    "def sigma(corpus,col1,col2):  #Retourne la matrice de covariance des colonnes d'un corpus\n",
    "    return np.cov(corpus[:,col1],corpus[:,col2],ddof = 0)\n",
    "\n",
    "M0 =moy(train0,0,1)\n",
    "M1 =moy(train1,0,1)\n",
    "M2 =moy(train2,0,1)\n",
    "\n",
    "S0 = sigma(train0,0,1)\n",
    "S1 = sigma(train1,0,1)\n",
    "S2 = sigma(train2,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase de classification\n",
    "- On cherche la vraissemblance qui est le r√©sultat de la fonction de densit√© de probabilit√© pour une loi Gaussienne bidimensionnelle, en utilisant les vecteurs moyennes et matrices de covariances pr√©cedemment obtenues et le param√®tre X qui est un vecteur contenant les valeurs colonnes 0 et 1 de la donn√©e √† classer.\n",
    "- On calcule la probabilit√© √† post√©riori = probabilit√© √† priori * vraissemblance\n",
    "- On classe les donn√©es  en s√©lectionnant la classe qui a la probabilit√© la plus √©lev√©e.\n",
    "- On r√©cup√®re ensuite le nombre d'erreurs en comparant les classes obtenues √† les classes r√©elles.\n",
    "- On teste ensuite diff√©rentes combinaisons de colonnes sur le corpus de dev (cr√©ation de mod√®les √† partir du corpus d'apprentissage) \n",
    "- On s√©lection le mod√®le qui a le moins d'erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En utilisant les descripteurs des colonnes 1 et 0  on a  13.333333333333334 % d'erreur(s)\n",
      "En utilisant les descripteurs des colonnes 2 et 0  on a  3.3333333333333335 % d'erreur(s)\n",
      "En utilisant les descripteurs des colonnes 2 et 1  on a  13.333333333333334 % d'erreur(s)\n",
      "En utilisant les descripteurs des colonnes 3 et 0  on a  10.0 % d'erreur(s)\n",
      "En utilisant les descripteurs des colonnes 3 et 1  on a  13.333333333333334 % d'erreur(s)\n",
      "En utilisant les descripteurs des colonnes 3 et 2  on a  10.0 % d'erreur(s)\n"
     ]
    }
   ],
   "source": [
    "def posteriori(X,M0,M1,M2,S0,S1,S2,P0,P1,P2):  #Calcul des probabilit√©s √† post√©riori avec gaussienne multidimensionnelle\n",
    "    p0 = P0*multivariate_normal.pdf(X,M0,S0)\n",
    "    p1 = P1*multivariate_normal.pdf(X,M1,S1)\n",
    "    p2 = P2*multivariate_normal.pdf(X,M2,S2)\n",
    "    return np.c_[p0,p1,p2]\n",
    "\n",
    "def classer(post):  # Classement par choix de la proba √† posteriori la plus √©lev√©\n",
    "    classes = []\n",
    "    a = post[:,0].size\n",
    "    for i in range(0,a):\n",
    "        liste = list(post[i])\n",
    "        classes.append(liste.index(max(liste)))\n",
    "    return np.array(classes)\n",
    "\n",
    "def erreur(origine,pred): # On v√©rifie le nombres d'erreurs de pr√©dictions\n",
    "    total = origine.size\n",
    "    erreur = 0\n",
    "    for i in range(0,total):\n",
    "        if(origine[i]!=pred[i]):\n",
    "            erreur+=1\n",
    "    return erreur/total\n",
    "            \n",
    "def affichErreur(col1,col2,erreur):\n",
    "    print(\"En utilisant les descripteurs des colonnes\",col1,\"et\",col2,\" on a \",erreur,\"% d'erreur(s)\")\n",
    "\n",
    "def action(col1,col2,data,target):    #Fait le calcul de moyennes, sigmas en fonction des colonnes, calcul probaPosteriori,\n",
    "    M0 =moy(train0,col1,col2)                       #classement puis erreur(s), retourne les classes  \n",
    "    M1 =moy(train1,col1,col2)\n",
    "    M2 =moy(train2,col1,col2)\n",
    "    S0 = sigma(train0,col1,col2)\n",
    "    S1 = sigma(train1,col1,col2)\n",
    "    S2 = sigma(train2,col1,col2)\n",
    "    probaPosteriori = posteriori(data[:,[col1,col2]],M0,M1,M2,S0,S1,S2,proba_class0,proba_class1,proba_class2)# calcul des probabilit√©s √† posteriori\n",
    "    classement = classer(probaPosteriori) # classer corpus de dev avec variables de colonnes col1 et col2\n",
    "    erreurs = erreur(target,classement) #nombre d'erreurs avec variables de colonnes col1 et col2\n",
    "    affichErreur(col1,col2,100*erreurs)\n",
    "    return classement\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,4):      #On calcul le nombre d'erreurs pour toutes les combinaisons de colonnes 6 possibles \n",
    "    for j in range(0,4):\n",
    "        if(i>j):\n",
    "            action(i,j,devData,devTarget) #question sur l'ordre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase de test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En prenant les colonnes 0 et 2 pour notre mod√®le, on a le moins d'erreur(s) on poursuit le test avec ce mod√®le\n",
    " - On r√©cup√®re les 3 moyennes et les 3 matrices de covariances obtenues √† partir des descripteurs (colonnes 0 et 1) sur le corpus d'apprentissage.\n",
    " - On calcule la probabilit√© √† post√©riori sur les 3 classes avec les param√®tres et les deux premi√®res colonnes du corpus de test.\n",
    " - On classe les donn√©es en s√©lectionnant la classe qui a la probabilit√© la plus √©lev√©e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En utilisant les descripteurs des colonnes 0 et 2  on a  5.0 % d'erreur(s)\n"
     ]
    }
   ],
   "source": [
    "prediction = action(0,2,testData,testTarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ConfusionMatrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-6fb7a385efb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatrice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfusionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ConfusionMatrix' is not defined"
     ]
    }
   ],
   "source": [
    "matrice = ConfusionMatrix(testTarget, prediction)\n",
    "print(matrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
