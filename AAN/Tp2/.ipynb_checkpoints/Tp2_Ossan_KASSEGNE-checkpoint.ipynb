{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2 Ossan KASSEGNE : Classifieur Bayésien "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.metrics' has no attribute 'jaccard_similarity_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-00ecce991132>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfusionMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas_ml/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#!/usr/bin/env python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelSeries\u001b[0m       \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minfo\u001b[0m                         \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__version__\u001b[0m     \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas_ml/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#!/usr/bin/env python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelFrame\u001b[0m       \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseries\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelSeries\u001b[0m     \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas_ml/core/frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimbaccessors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimbaccessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mskaccessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmaccessors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msmaccessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnsaccessors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msnsaccessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas_ml/skaccessors/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearModelMethods\u001b[0m                 \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mManifoldMethods\u001b[0m                        \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetricsMethods\u001b[0m                          \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelSelectionMethods\u001b[0m           \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeighborsMethods\u001b[0m                      \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas_ml/skaccessors/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    254\u001b[0m _true_pred_methods = (_classification_methods + _regression_methods\n\u001b[1;32m    255\u001b[0m                       + _cluster_methods)\n\u001b[0;32m--> 256\u001b[0;31m \u001b[0m_attach_methods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMetricsMethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_wrap_target_pred_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_true_pred_methods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas_ml/core/accessor.py\u001b[0m in \u001b[0;36m_attach_methods\u001b[0;34m(cls, wrap_func, methods)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0m_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} already has '{1}' method\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.metrics' has no attribute 'jaccard_similarity_score'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from math import pi,exp,sqrt\n",
    "from scipy.stats import multivariate_normal\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "#print (iris.data)\n",
    "#print(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ciris = np.c_[iris.data.reshape(len(iris.data), -1), iris.target.reshape(len(iris.target), -1)]\n",
    "np.random.seed(987654321)\n",
    "np.random.shuffle(Ciris)\n",
    "shuffledIrisData = Ciris[ :, :iris.data.size//len(iris.data)].reshape(iris.data.shape)\n",
    "shuffledIrisTarget = Ciris[ :, iris.data.size//len(iris.data) :].reshape(iris.target.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData,devData,testData = shuffledIrisData[:100],shuffledIrisData[100:130],shuffledIrisData[130:]\n",
    "trainTarget,devTarget,testTarget = shuffledIrisTarget[:100],shuffledIrisTarget[100:130],shuffledIrisTarget[130:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase d'apprentissage (utilisation de sepal length et sepal width/ colonnes 0 et 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilité à priori sur le modèle d'apprentissatige\n",
    "- On récupère la probabilité à priori de chaque classe dans le corpus d'apprentissage\n",
    "- Probabilités à priori\n",
    " Classe 0 =  0.32 \n",
    " Classe 1 =  0.37 \n",
    " Classe 2 =  0.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##On récupère le nombre de classes 0,1 et 2\n",
    "total = trainTarget.size\n",
    "classes = list(trainTarget)\n",
    "proba_class0 = (classes.count(0))/total\n",
    "proba_class1 = (classes.count(1))/total\n",
    "proba_class2 = (classes.count(2))/total\n",
    "print(\"Probabilités à priori\\n\",\"Classe 0 = \",proba_class0,\"\\n\",\"Classe 1 = \",proba_class1,\"\\n\",\"Classe 2 = \",proba_class2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation du corpus d'apprentissage en fonction des classes\n",
    " On sépare les corpus d'apprentissage en fonction des 3 classes pour le calcul des moyennes et des matrices de covariance de chacune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFull = np.c_[trainData,trainTarget]\n",
    "train0,train1,train2 = [] ,[], []\n",
    "for i in range(0,100):\n",
    "    if(trainFull[i][4] == 0):\n",
    "        train0.append(trainFull[i])\n",
    "    elif (trainFull[i][4] == 1):\n",
    "        train1.append(trainFull[i])\n",
    "    else :\n",
    "        train2.append(trainFull[i])\n",
    "train0 = np.array(train0)\n",
    "train1 = np.array(train1)\n",
    "train2 = np.array(train2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moyennes, Sigma suivant le descripteur \"sepal length\" et \"sepal width\" en fonction des classes\n",
    "On calcule le vecteur des moyennes et la matrices de covariance de chaque classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp = sepal length , sw = sepal width\n",
    "\n",
    "def moy(corpus, col1,col2):    #Retourne le vecteur des moyennes d'un corpus\n",
    "    return np.r_[np.mean(corpus[:,col1]),np.mean(corpus[:,col2])]\n",
    "\n",
    "def sigma(corpus,col1,col2):  #Retourne la matrice de covariance des colonnes d'un corpus\n",
    "    return np.cov(corpus[:,col1],corpus[:,col2],ddof = 0)\n",
    "\n",
    "M0 =moy(train0,0,1)\n",
    "M1 =moy(train1,0,1)\n",
    "M2 =moy(train2,0,1)\n",
    "\n",
    "S0 = sigma(train0,0,1)\n",
    "S1 = sigma(train1,0,1)\n",
    "S2 = sigma(train2,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase de classification\n",
    "- On cherche la vraissemblance qui est le résultat de la fonction de densité de probabilité pour une loi Gaussienne bidimensionnelle, en utilisant les vecteurs moyennes et matrices de covariances précedemment obtenues et le paramètre X qui est un vecteur contenant les valeurs colonnes 0 et 1 de la donnée à classer.\n",
    "- On calcule la probabilité à postériori = probabilité à priori * vraissemblance\n",
    "- On classe les données  en sélectionnant la classe qui a la probabilité la plus élevée.\n",
    "- On récupère ensuite le nombre d'erreurs en comparant les classes obtenues à les classes réelles.\n",
    "- On teste ensuite différentes combinaisons de colonnes sur le corpus de dev (création de modèles à partir du corpus d'apprentissage) \n",
    "- On sélection le modèle qui a le moins d'erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En utilisant les descripteurs des colonnes 1 et 0  on a  13.333333333333334 % d'erreur(s)\n",
      "En utilisant les descripteurs des colonnes 2 et 0  on a  3.3333333333333335 % d'erreur(s)\n",
      "En utilisant les descripteurs des colonnes 2 et 1  on a  13.333333333333334 % d'erreur(s)\n",
      "En utilisant les descripteurs des colonnes 3 et 0  on a  10.0 % d'erreur(s)\n",
      "En utilisant les descripteurs des colonnes 3 et 1  on a  13.333333333333334 % d'erreur(s)\n",
      "En utilisant les descripteurs des colonnes 3 et 2  on a  10.0 % d'erreur(s)\n"
     ]
    }
   ],
   "source": [
    "def posteriori(X,M0,M1,M2,S0,S1,S2,P0,P1,P2):  #Calcul des probabilités à postériori avec gaussienne multidimensionnelle\n",
    "    p0 = P0*multivariate_normal.pdf(X,M0,S0)\n",
    "    p1 = P1*multivariate_normal.pdf(X,M1,S1)\n",
    "    p2 = P2*multivariate_normal.pdf(X,M2,S2)\n",
    "    return np.c_[p0,p1,p2]\n",
    "\n",
    "def classer(post):  # Classement par choix de la proba à posteriori la plus élevé\n",
    "    classes = []\n",
    "    a = post[:,0].size\n",
    "    for i in range(0,a):\n",
    "        liste = list(post[i])\n",
    "        classes.append(liste.index(max(liste)))\n",
    "    return np.array(classes)\n",
    "\n",
    "def erreur(origine,pred): # On vérifie le nombres d'erreurs de prédictions\n",
    "    total = origine.size\n",
    "    erreur = 0\n",
    "    for i in range(0,total):\n",
    "        if(origine[i]!=pred[i]):\n",
    "            erreur+=1\n",
    "    return erreur/total\n",
    "            \n",
    "def affichErreur(col1,col2,erreur):\n",
    "    print(\"En utilisant les descripteurs des colonnes\",col1,\"et\",col2,\" on a \",erreur,\"% d'erreur(s)\")\n",
    "\n",
    "def action(col1,col2,data,target):    #Fait le calcul de moyennes, sigmas en fonction des colonnes, calcul probaPosteriori,\n",
    "    M0 =moy(train0,col1,col2)                       #classement puis erreur(s), retourne les classes  \n",
    "    M1 =moy(train1,col1,col2)\n",
    "    M2 =moy(train2,col1,col2)\n",
    "    S0 = sigma(train0,col1,col2)\n",
    "    S1 = sigma(train1,col1,col2)\n",
    "    S2 = sigma(train2,col1,col2)\n",
    "    probaPosteriori = posteriori(data[:,[col1,col2]],M0,M1,M2,S0,S1,S2,proba_class0,proba_class1,proba_class2)# calcul des probabilités à posteriori\n",
    "    classement = classer(probaPosteriori) # classer corpus de dev avec variables de colonnes col1 et col2\n",
    "    erreurs = erreur(target,classement) #nombre d'erreurs avec variables de colonnes col1 et col2\n",
    "    affichErreur(col1,col2,100*erreurs)\n",
    "    return classement\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,4):      #On calcul le nombre d'erreurs pour toutes les combinaisons de colonnes 6 possibles \n",
    "    for j in range(0,4):\n",
    "        if(i>j):\n",
    "            action(i,j,devData,devTarget) #question sur l'ordre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase de test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En prenant les colonnes 0 et 2 pour notre modèle, on a le moins d'erreur(s) on poursuit le test avec ce modèle\n",
    " - On récupère les 3 moyennes et les 3 matrices de covariances obtenues à partir des descripteurs (colonnes 0 et 1) sur le corpus d'apprentissage.\n",
    " - On calcule la probabilité à postériori sur les 3 classes avec les paramètres et les deux premières colonnes du corpus de test.\n",
    " - On classe les données en sélectionnant la classe qui a la probabilité la plus élevée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En utilisant les descripteurs des colonnes 0 et 2  on a  5.0 % d'erreur(s)\n"
     ]
    }
   ],
   "source": [
    "prediction = action(0,2,testData,testTarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ConfusionMatrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-6fb7a385efb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatrice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfusionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ConfusionMatrix' is not defined"
     ]
    }
   ],
   "source": [
    "matrice = ConfusionMatrix(testTarget, prediction)\n",
    "print(matrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
